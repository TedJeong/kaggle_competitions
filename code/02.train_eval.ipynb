{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Santander-Product-Recommendation-Problem Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "st = time.time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn = pd.read_csv('../input/train_append_lb_lag.csv').fillna(0)\n",
    "target = pd.DataFrame(pickle.load(open('../input/target.pkl','rb')), columns=['target'])\n",
    "tst = pd.read_csv('../input/test_append_lb_lag.csv').fillna(0)\n",
    "print(trn.shape, target.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in trn.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn.columns == tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Erem_targets = [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]  # 18 classes\n",
    "trn = trn[target['target'].isin(rem_targets)]\n",
    "target = target[target['target'].isin(rem_targets)]\n",
    "target = LabelEncoder().fit_transform(target)\n",
    "\n",
    "for t in np.unique(target):\n",
    "    print(t, sum(target==t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "def evaluate(x, y, model):\n",
    "    trn_scores = dict(); vld_scores = dict()\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=777)\n",
    "    for t_ind, v_ind in sss.split(x,y):\n",
    "        # split data\n",
    "        x_trn, x_vld = x.iloc[t_ind], x.iloc[v_ind]\n",
    "        y_trn, y_vld = y[t_ind], y[v_ind]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_trn, y_trn)\n",
    "        \n",
    "        # eval _ trn        \n",
    "        preds = model.predict_proba(x_trn)\n",
    "\n",
    "        log_scores = trn_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_trn, preds))\n",
    "        trn_scores['log loss'] = log_scores\n",
    "\n",
    "        # eval _ vld\n",
    "        preds = model.predict_proba(x_vld)\n",
    "\n",
    "        log_scores = vld_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_vld, preds))\n",
    "        vld_scores['log loss'] = log_scores\n",
    "    return trn_scores, vld_scores\n",
    "\n",
    "def print_scores(trn_scores, vld_scores):\n",
    "    prefix = '        '\n",
    "    cols = ['log loss']\n",
    "    print('='*50)\n",
    "    print('TRAIN EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "    print('='*50)\n",
    "    print('VALID EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "\n",
    "def print_time(end, start):\n",
    "    print('='*50)\n",
    "    elapsed = end - start\n",
    "    print('{} secs'.format(round(elapsed)))\n",
    "    \n",
    "def fit_and_eval(trn, target, model):\n",
    "    trn_scores, vld_scores = evaluate(trn,target,model)\n",
    "    print_scores(trn_scores, vld_scores)\n",
    "    print_time(time.time(), st)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOLUTION_NUM = \"4\"\n",
    "\n",
    "# XGB Model Param\n",
    "num_round = 5\n",
    "early_stop = 10\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "\n",
    "    # 모델 복잡도\n",
    "    'max_depth': 5, # 높을 수록 복잡\n",
    "    'gamma': 3,    # 낮을 수록 복잡\n",
    "    'min_child_weight': 2, # 낮을 수록 복잡\n",
    "\n",
    "    # 랜덤 샘플링을 통한 정규화\n",
    "    'colsample_bylevel': 0.7,\n",
    "    'colsample_bytree': 1,\n",
    "    'subsample': 0.8,\n",
    "\n",
    "    # 정규화\n",
    "    'reg_alpha': 2,\n",
    "    'reg_lambda': 3,\n",
    "\n",
    "    # 학습 속도\n",
    "    'learning_rate': 0.02,\n",
    "\n",
    "    # 기본 설정\n",
    "    'nthread': 4,\n",
    "    'num_class': 18,\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 777,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGB Model score\n",
    "def print_scores_with_logs(trn_scores, vld_scores):\n",
    "    prefix = '        '\n",
    "    cols = ['log loss']\n",
    "\n",
    "    f = open(\"sol_\"+SOLUTION_NUM+\"_log.result\",\"a\")\n",
    "\n",
    "    print('='*50)\n",
    "    print('TRAIN EVAL')\n",
    "\n",
    "    f.write('='*50)\n",
    "    f.write('TRAIN EVAL')\n",
    "\n",
    "\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "        f.write('-'*50)\n",
    "        f.write('# {}'.format(col))\n",
    "        f.write('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        f.write('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "\n",
    "    print('='*50)\n",
    "    print('VALID EVAL')\n",
    "\n",
    "    f.write('='*50)\n",
    "    f.write('VALID EVAL')\n",
    "\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "\n",
    "        f.write('-'*50)\n",
    "        f.write('# {}'.format(col))\n",
    "        f.write('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        f.write('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "    f.close()\n",
    "\n",
    "def print_time(end, start):\n",
    "    f = open(\"sol_\"+SOLUTION_NUM+\"_log.result\",\"a\")\n",
    "\n",
    "    print('='*50)\n",
    "    f.write('='*50)\n",
    "    elapsed = end - start\n",
    "    print('{} secs'.format(round(elapsed)))\n",
    "    f.write('{} secs'.format(round(elapsed)))\n",
    "    f.close()\n",
    "\n",
    "def fit_and_eval(trn, target, model):\n",
    "    trn_scores, vld_scores = evaluate(trn,target,model)\n",
    "    print_scores_with_logs(trn_scores, vld_scores)\n",
    "    print_time(time.time(), st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "#RandomForestClassifier, Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_model = RandomForestClassifier(max_depth=10, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, rf_model)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Xgboost\n",
    "evaluate_xgb(trn,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글에 직접 결과물 제출하기\n",
    "    - MAP@7 평가척도를 기반 (https://www.kaggle.com/c/santander-product-recommendation/details/evaluation)\n",
    "    - 유저당 상위 7개의 제품을 추천해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print('='*50)\n",
    "print('# Test shape : {}'.format(tst.shape))\n",
    "\n",
    "model = RandomForestClassifier(max_depth=20, n_jobs=-1, random_state=777)\n",
    "model.fit(trn,target)\n",
    "\n",
    "preds = model.predict_proba(tst)\n",
    "preds = np.fliplr(np.argsort(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XgBoost\n",
    "dtrn = xgb.DMatrix(trn, label= target)\n",
    "num_round = num_round # 평가 함수 기반 최적의 num_round 수치 지정\n",
    "bst = xgb.train(xgb_params, dtrn, num_round, verbose_eval=True)\n",
    "\n",
    "dtst = xgb.DMatrix(tst)\n",
    "preds = bst.predict(dtst)\n",
    "preds = np.fliplr(np.argsort(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "        'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\n",
    "        'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "        'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "        'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "        'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "        'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "        'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "target_cols = [cols[i] for i, col in enumerate(cols) if i in rem_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in preds:\n",
    "    top_products = []\n",
    "    for i, product in enumerate(pred):\n",
    "        top_products.append(target_cols[product])\n",
    "        if i == 6:\n",
    "            break\n",
    "    final_preds.append(' '.join(top_products))\n",
    "\n",
    "temp = pd.read_csv('../input/test_clean.csv')\n",
    "test_id = temp['ncodpers']\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "file_name = datetime.now().strftime(\"result_%Y%m%d%H%M%S\") + '.csv'\n",
    "out_df.to_csv(os.path.join('../output',file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물 출력은 https://www.kaggle.com/c/santander-product-recommendation/submissions/attach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나만의 머신러닝 파이프라인 흐름도(Flow Chart) 기록하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원천 데이터\n",
    "    - .\n",
    "\n",
    "- 전처리\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 \n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - .\n",
    "\n",
    "- 검증 결과 \n",
    "    - .\n",
    "\n",
    "- 실제 결과 \n",
    "    - ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시\n",
    "\n",
    "- 원천 데이터 \n",
    "    - Kaggle 경진대회 데이터 train_ver2.csv, test_ver2.csv (Link: https://www.kaggle.com/c/santander-product-recommendation/data)\n",
    "\n",
    "\n",
    "- 전처리 \n",
    "    - 결측값을 .fillna 함수를 통해 0으로 대체. (기존 데이터에 0이 존재할 경우 -1로 대체)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension:\n",
    "    - trn : (45619, 246)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 246)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링\n",
    "    - age_log : log(age + 1)\n",
    "    - ind..._lag_one : 5월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_two : 4월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_thr : 3월 사용자별 금융상품 보유현황\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension:\n",
    "    - trn : (45619, 250)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 250)\n",
    "\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - RandomForest : max_depth = 20 로 복잡도 조정\n",
    "\n",
    "\n",
    "- 검증 결과 \n",
    "    - trn logloss : 1.18\n",
    "    - vld logloss : 1.28\n",
    "\n",
    "\n",
    "- 실제 결과 \n",
    "    - Public Leaderboard : 0.025984\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "    - RandomForest vs ExtraTrees 의 차이란?\n",
    "        - P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006\n",
    "        - 1) ET의 경우, 변수 샘플링을 boostrap 샘플이 아닌 전체 데이터에서 취한다.\n",
    "        - 2) ET의 경우, 샘플내 분포에 상관없이 완전한 임의 샘플링으로 데이터 샘플을 취한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
